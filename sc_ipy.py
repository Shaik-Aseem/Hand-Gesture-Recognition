# -*- coding: utf-8 -*-
"""Skillcraft_Task_04_HandGesture.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FW27-kf3lDxJBLLVTAuasI-pIbG-z6Vv
"""

!pip install tensorflow opencv-python seaborn scikit-learn matplotlib

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

!git clone https://github.com/ardamavi/Sign-Language-Digits-Dataset.git

DATA_DIR = "./Sign-Language-Digits-Dataset/Dataset"
print("Dataset folder:", DATA_DIR)
print("Classes available:", os.listdir(DATA_DIR))

IMG_SIZE = 64
images, labels = [], []
classes = os.listdir(DATA_DIR)

for idx, gesture in enumerate(classes):
    gesture_path = os.path.join(DATA_DIR, gesture)
    for file in os.listdir(gesture_path):
        img_path = os.path.join(gesture_path, file)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            continue
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
        images.append(img)
        labels.append(idx)

# Convert to arrays
X = np.array(images).reshape(-1, IMG_SIZE, IMG_SIZE, 1).astype('float32') / 255.0
y = to_categorical(np.array(labels), num_classes=len(classes))

print("âœ… Dataset loaded:", X.shape, y.shape)
print("Classes:", classes)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Train:", X_train.shape, y_train.shape)
print("Test:", X_test.shape, y_test.shape)

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(len(classes), activation='softmax')
])

model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(
    X_train, y_train,
    validation_split=0.1,
    epochs=25,
    batch_size=32,
    verbose=1
)

test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"\nðŸŽ¯ Final Test Accuracy: {test_acc*100:.2f}%")

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend(); plt.title("Accuracy"); plt.xlabel("Epochs"); plt.ylabel("Accuracy")

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend(); plt.title("Loss"); plt.xlabel("Epochs"); plt.ylabel("Loss")

plt.show()

y_pred = np.argmax(model.predict(X_test), axis=1)
y_true = np.argmax(y_test, axis=1)

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
plt.xlabel("Predicted"); plt.ylabel("True"); plt.title("Confusion Matrix")
plt.show()

print("\nClassification Report:\n", classification_report(y_true, y_pred, target_names=classes))

model.save("hand_gesture_model.keras")

from tensorflow.keras.models import load_model
model2 = load_model("hand_gesture_model.keras")
print("âœ… Model loaded successfully!")